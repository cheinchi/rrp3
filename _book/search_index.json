[["index.html", "基于R的文献复刻：利用中国微观数据库 前言 0.1 缘起 0.2 为何是R 0.3 如何食用 0.4 R入门", " 基于R的文献复刻：利用中国微观数据库 黄建祺 2023-06-13 前言 0.1 缘起 突然想要研究某一个中国的微观数据库，但又无奈苯人掌握Stata技法有限，想要再去学有点学不动了。忽然一次在网上看到林敏杰老师的《CFPS 之R语言学习笔记》 瞬间为我打开了一扇窗，所以尝试使用R来实现一些在实证经济学的一些应用或称为复刻，另外加上一丁点的探索。之前也看到国外的在利用shiny搭建的网站1做的文献复刻，因此就有一些用R来做的冲动。 0.2 为何是R 为何选择使用R呢。现在在复刻文献的主流方法是使用Stata，同时在一些wiki 或者期刊网站、数据网站2 上大部分是使用stata来实现复刻或者源代码的。但目前，一些经济学、政治学学者开始在利用R做基本的计量分析，甚至开发专门的R包来实现一些高级计量方法，在R中有很多超越于Stata的优势。 0.3 如何食用 这本书是基于中国的几大微观数据库及相关的顶刊上的文章为主要内容写成的自我技术修炼笔记，为最大化他的社会效益，以bookdown形式生成。希望能够对你有所帮助。 在经济学研究中，近些年来对于微观数据的使用变得尤为重要，尤其是大型的微观数据库的使用。但常用的处理方法往往是选择在Stata中进行操作。但在另一方面，R相对于Stata的使用有其独特的优势，尤其是在使用多个数据框操作时候，在今天的一篇文章中很难就单单一个数据源就能完成一篇好的文章写作，因此对于不同数据源进行交互性操作愈发重要。因此有必要使用R来对数据进行相应的操作。同时R也是支持于.dta数据的读取。 同时再深了讲在不同语言之间的比较，Aruoba and Fernández-Villaverde (2015) 有对比不同的编程语言的运行速度，同时需要强调的是C++/Fortran/Java对比其他的语言是更难学习的，由其本身的特性所决定的，所以对于经济学家来说没有那么多的时间成本学习前三种语言，但可以作为一个参照。最后发现Julia的表现尤其突出，甚至超过于Java，远甩身后的Matlab好几米；Python与R基本上持平，但一用上Pypy编译器立马加速；最慢的是Mathemetica（虽然我也没用过） 3 图0.1: 图来自上述文章 Julia的强劲表现让很多经济学者极力推崇4 相关的学习材料在Quantecon 就很丰富了。 但我们这里并不需要大量的数据，因此对于编译速度的要求并不高，RStudio能够满足日常的基本需要。 0.4 R入门 关于R的入门这里不多介绍，bookdown中有大量关于R的入门书籍。这里可以做出一定的推荐： 英文比较好的话： 官方manual R for Data Science modern dive Big book of R：和字典一样厚，作者至今还在更新。 看中文更有优势的话： R语言教程 数据科学中的R语言 当然因为这里主要介绍一些经济学论文和经济学方法，不可避免要学习和使用计量及R上的应用。同样有很多出色的线上教材。 Introduction to Econometric with R Causal Inference: The Mixtape: 有三种语言的代码任你选择。 需要注意的是在R中进行数据处理，必然无法避开学习和使用tidyverse，因为这才是数据科学学习R的优势之处。 这篇所需要使用的R包：使用pacman免去验证是否安装的烦恼。 if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman p_load(tidyverse, purrr, haven, visdat, sf, units, lwgeom, rmapshaper, tictoc) 参考文献 "],["r-applied-econometrics-workflow.html", "1 R-Applied Econometrics Workflow 1.1 Stargazer 1.2 在RStudio中写作 1.3 Presentation", " 1 R-Applied Econometrics Workflow 应用微观的经济学家的工作流会选择使用Stata（宏观学者可能会用Matlab,dynare,Julia）加上LaTeX/Lyx（包括做slides），若可能需要的话加上一些数据库的知识。 这里使用wooldridge包中大学GPA数据来作为演示。 1.1 Stargazer library(wooldridge) library(stargazer) data(&quot;gpa1&quot;) 1.1.1 描述性统计 选出我们所关心的几个变量进行描述性统计。 gpa_var &lt;- gpa1%&gt;% select(colGPA,hsGPA,ACT,skipped) 这里调用psych来进行描述性统计，但描述性统计的包并不仅限于此，甚至使用dplyr中的summarize也是一个比较好的选择。 library(psych) stargazer(describe(gpa_var,trim = F,skew = F,ranges = F),type = &quot;html&quot;) Statistic N Mean St. Dev. Min Max vars 4 2.500 1.291 1 4 n 4 141.000 0.000 141 141 mean 4 7.923 10.871 1.076 24.156 sd 4 1.156 1.179 0.320 2.844 se 4 0.097 0.099 0.027 0.240 需要记得的是在option中添加results='asis'才会将输出代码以raw code的形式放在文本中。这里因为是html格式的缘故，因此将输出格式输出为html。若使用LaTeX输出格式，则最终在tex中所呈现的状态会是 stargazer(describe(gpa_var,trim = F,skew = F,ranges = F),type = &quot;text&quot;) ## ## ========================================= ## Statistic N Mean St. Dev. Min Max ## ----------------------------------------- ## vars 4 2.500 1.291 1 4 ## n 4 141.000 0.000 141 141 ## mean 4 7.923 10.871 1.076 24.156 ## sd 4 1.156 1.179 0.320 2.844 ## se 4 0.097 0.099 0.027 0.240 ## ----------------------------------------- 1.1.2 回归结果报告 先试图去回归一个基准组： reg.base &lt;- colGPA~hsGPA lm.base &lt;- lm(reg.base,gpa_var) 一个较为常用的快速查看回归结果的方法是使用summary()函数。 summary(lm.base) ## ## Call: ## lm(formula = reg.base, data = gpa_var) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.85220 -0.26274 -0.04868 0.28902 0.88551 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.41543 0.30694 4.611 8.98e-06 *** ## hsGPA 0.48243 0.08983 5.371 3.21e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.34 on 139 degrees of freedom ## Multiple R-squared: 0.1719, Adjusted R-squared: 0.1659 ## F-statistic: 28.85 on 1 and 139 DF, p-value: 3.211e-07 再添加一组控制组： gpa.control &lt;- colGPA~hsGPA+ACT+skipped lm.control &lt;- lm(gpa.control,data = gpa_var) lm.list &lt;- list(lm.base,lm.control) stargazer(lm.list,type = &quot;html&quot;) Dependent variable: colGPA (1) (2) hsGPA 0.482*** 0.412*** (0.090) (0.094) ACT 0.015 (0.011) skipped -0.083*** (0.026) Constant 1.415*** 1.390*** (0.307) (0.332) Observations 141 141 R2 0.172 0.234 Adjusted R2 0.166 0.217 Residual Std. Error 0.340 (df = 139) 0.329 (df = 137) F Statistic 28.845*** (df = 1; 139) 13.919*** (df = 3; 137) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 当然，在回归结果报告还是在描述性统计中，最终的显示格式可以根据不同期刊来进行调整，比如来一个AER： stargazer(lm.list,type = &quot;html&quot;,style = &quot;aer&quot;) colGPA (1) (2) hsGPA 0.482*** 0.412*** (0.090) (0.094) ACT 0.015 (0.011) skipped -0.083*** (0.026) Constant 1.415*** 1.390*** (0.307) (0.332) Observations 141 141 R2 0.172 0.234 Adjusted R2 0.166 0.217 Residual Std. Error 0.340 (df = 139) 0.329 (df = 137) F Statistic 28.845*** (df = 1; 139) 13.919*** (df = 3; 137) Notes: ***Significant at the 1 percent level. **Significant at the 5 percent level. *Significant at the 10 percent level. 若是在latex中显示就会是这样的： 1.2 在RStudio中写作 当然要有一整套的workflow不仅仅是将原代码c-p到overleaf，还需要在Rstudio中一整套的工作流程。 在RStudio中进行输出，我们会考虑使用bookdown这个包来进行编辑之间的论文，bookdownplus中有较多关于国内高校的毕业论文bookdown模版，能够直接输入相关命令获取模版。 同时，从最初的Pandoc，再到quarto，typst在近些年得到兴起，其对于格式的多样性支持能够帮助我们获取。但这些新兴文本输入工具可能使用并非广泛，比较常用的方法仍然是选择LaTeX+R，基本上可以实现大部分的功能 stargazer(describe(gpa_var,trim = F,skew = F,ranges = F), type = &quot;latex&quot;, out = &quot;olsreg.tex&quot;) ## ## % Table created by stargazer v.5.2.3 by Marek Hlavac, Social Policy Institute. E-mail: marek.hlavac at gmail.com ## % Date and time: Tue, Jun 13, 2023 - 17:06:55 ## \\begin{table}[!htbp] \\centering ## \\caption{} ## \\label{} ## \\begin{tabular}{@{\\extracolsep{5pt}}lccccc} ## \\\\[-1.8ex]\\hline ## \\hline \\\\[-1.8ex] ## Statistic &amp; \\multicolumn{1}{c}{N} &amp; \\multicolumn{1}{c}{Mean} &amp; \\multicolumn{1}{c}{St. Dev.} &amp; \\multicolumn{1}{c}{Min} &amp; \\multicolumn{1}{c}{Max} \\\\ ## \\hline \\\\[-1.8ex] ## vars &amp; 4 &amp; 2.500 &amp; 1.291 &amp; 1 &amp; 4 \\\\ ## n &amp; 4 &amp; 141.000 &amp; 0.000 &amp; 141 &amp; 141 \\\\ ## mean &amp; 4 &amp; 7.923 &amp; 10.871 &amp; 1.076 &amp; 24.156 \\\\ ## sd &amp; 4 &amp; 1.156 &amp; 1.179 &amp; 0.320 &amp; 2.844 \\\\ ## se &amp; 4 &amp; 0.097 &amp; 0.099 &amp; 0.027 &amp; 0.240 \\\\ ## \\hline \\\\[-1.8ex] ## \\end{tabular} ## \\end{table} 在LaTeX中使用下述语法即可直接在同一文件夹中导入回归表格。 \\include{olsreg.tex} 其好处在于随时可以对回归结果进行更新。 1.3 Presentation 同样的道理，一个好的论文不仅仅是在写作，也还需要进行sale，学界通常情况下会选择使用beamer来进行制作slides。 同样R中也是支持Beamer，对应的介绍在统计之都中有极为详细的介绍。但在这里更加推崇的是使用xaringan，一个以javascripts为基础的网页slides制作包。相关的介绍可以在Yihui个人网站。 "],["土地流转研究.html", "2 土地流转研究 2.1 载入包 2.2 导入数据 2.3 查看变量标签 2.4 数据规整 2.5 模型建立", " 2 土地流转研究 数据来源：CFPS 本章主要参考四川师范大学王敏杰老师的研究笔记 2.1 载入包 library(tidyverse) library(purrr) library(haven) library(visdat) 2.2 导入数据 cfps2010family &lt;- read_dta(&quot;/Volumes/Expansion/micro-base-data/cfps/2010/cfps2010famecon_202008.dta&quot;) cfps2010family %&gt;% select(fid,urban, starts_with(&quot;fk201_a&quot;)) %&gt;% glimpse() ## Rows: 14,797 ## Columns: 8 ## $ fid &lt;dbl+lbl&gt; 110001, 110003, 110005, 110006, 110007, 110009, 110010, … ## $ urban &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ fk201_a_1 &lt;dbl+lbl&gt; -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, … ## $ fk201_a_2 &lt;dbl+lbl&gt; -8.0, -8.0, -8.0, -8.0, 2.5, -8.0, -8.0, -8.0, -8.0, -8… ## $ fk201_a_3 &lt;dbl+lbl&gt; -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, … ## $ fk201_a_4 &lt;dbl+lbl&gt; -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, … ## $ fk201_a_5 &lt;dbl+lbl&gt; -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, … ## $ fk201_a_6 &lt;dbl+lbl&gt; -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, -8, … 2.3 查看变量标签 对于原有数据，都是存在一个标签来显示原始的问题形式，因此我们可以先查看我们想要找的问题的标签是否对应。先创建一个get_var_label的函数。 library(purrr) get_var_label &lt;- function(dta) { labels &lt;- map(dta, function(x) attr(x, &quot;label&quot;)) data_frame( name = names(labels), label = as.character(labels) ) } 根据观察原有标签，我们可知道fk201_a_n的变量都是拥有的农业资产，fk202_a_n、fk203_a_n和fk204_a_n分别是经营、转租入和转租出多少农业资产。 cfps2010family %&gt;% select(urban, starts_with(&quot;fk201_a&quot;)) %&gt;% get_var_label() %&gt;% head() ## Warning: `data_frame()` was deprecated in tibble 1.1.0. ## ℹ Please use `tibble()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## # A tibble: 6 × 2 ## name label ## &lt;chr&gt; &lt;chr&gt; ## 1 urban 基于国家统计局资料的城乡分类变量 ## 2 fk201_a_1 您家拥有多少亩水田 ## 3 fk201_a_2 您家拥有多少亩旱地 ## 4 fk201_a_3 您家拥有多少亩林地 ## 5 fk201_a_4 您家拥有多少亩果园 ## 6 fk201_a_5 您家拥有多少亩草场 ur_and_land &lt;- cfps2010family %&gt;% select(urban, starts_with(&quot;fk201_a&quot;)) %&gt;% map(~ count(data.frame(x = .x), x)) ur_and_land$urban ## x n ## 1 0 7694 ## 2 1 7103 这里使用了map函数来构建一个映射，映射到一个累加求和，第一张表是农业户口和城镇户口的数量对比，后面的表都是密度分布。 2.4 数据规整 library(naniar) cfps2010family %&gt;% select(urban, starts_with(&quot;fk201_a&quot;)) %&gt;% miss_var_summary() ## # A tibble: 7 × 3 ## variable n_miss pct_miss ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 urban 0 0 ## 2 fk201_a_1 0 0 ## 3 fk201_a_2 0 0 ## 4 fk201_a_3 0 0 ## 5 fk201_a_4 0 0 ## 6 fk201_a_5 0 0 ## 7 fk201_a_6 0 0 基本上是没有缺失数据。 library(visdat) cfps2010family %&gt;% select(urban, starts_with(&quot;fk201_a&quot;)) %&gt;% vis_dat() 为防止包之间的函数冲突，使用conflicted来prefer到dplyr中的filter。 library(conflicted) conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;) cfps2010family %&gt;% select(urban, starts_with(&quot;fk2_s&quot;))%&gt;% filter(urban == 0) ## # A tibble: 7,694 × 6 ## urban fk2_s_1 fk2_s_2 fk2_s_3 fk2_s_4 fk2_s_5 ## &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 0 [乡村] 4 [果园] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 2 0 [乡村] 2 [旱地] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 3 0 [乡村] 4 [果园] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 4 0 [乡村] 4 [果园] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 5 0 [乡村] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 6 0 [乡村] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 7 0 [乡村] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 8 0 [乡村] 6 [池塘] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 9 0 [乡村] 4 [果园] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## 10 0 [乡村] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] -8 [不适用] ## # ℹ 7,684 more rows 先找出有经营土地的家户：并不考虑是否是自己拥有还是转租入。 a &lt;- cfps2010family %&gt;% select(fid,urban, starts_with(&quot;fk201_a&quot;)) %&gt;% filter_at(vars(starts_with(&quot;fk201_a&quot;)), any_vars(. &gt; 0)) a ## # A tibble: 7,688 × 8 ## fid urban fk201_a_1 fk201_a_2 fk201_a_3 fk201_a_4 fk201_a_5 fk201_a_6 ## &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 110007 1 [城… -8 [不适… 2.5 … -8 [不适… -8 [不适… -8 [不适… -8 [不适… ## 2 120033 1 [城… -8 [不适… -8 [不适… -8 [不适… 0.900 … -8 [不适… -8 [不适… ## 3 120073 0 [乡… -8 [不适… -8 [不适… -8 [不适… 5.10 … -8 [不适… -8 [不适… ## 4 120074 0 [乡… -8 [不适… 1.80 … -8 [不适… -8 [不适… -8 [不适… -8 [不适… ## 5 120076 0 [乡… -8 [不适… -8 [不适… -8 [不适… 6 … -8 [不适… -8 [不适… ## 6 120080 0 [乡… -8 [不适… -8 [不适… -8 [不适… -8 [不适… -8 [不适… 38 … ## 7 120081 0 [乡… -8 [不适… -8 [不适… -8 [不适… 4 … -8 [不适… -8 [不适… ## 8 120084 0 [乡… -8 [不适… -8 [不适… -8 [不适… 1.5 … -8 [不适… -8 [不适… ## 9 120087 0 [乡… -8 [不适… -8 [不适… -8 [不适… 3 … -8 [不适… -8 [不适… ## 10 120088 0 [乡… -8 [不适… 1.5 … -8 [不适… -8 [不适… -8 [不适… -8 [不适… ## # ℹ 7,678 more rows 再将负值转变为0。 a %&gt;% mutate_at(vars(starts_with(&quot;fk201_a&quot;)), funs(replace(., . &lt; 0, 0))) ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## # A tibble: 7,688 × 8 ## fid urban fk201_a_1 fk201_a_2 fk201_a_3 fk201_a_4 fk201_a_5 fk201_a_6 ## &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 110007 1 [城… 0 2.5 0 0 0 0 ## 2 120033 1 [城… 0 0 0 0.900 0 0 ## 3 120073 0 [乡… 0 0 0 5.10 0 0 ## 4 120074 0 [乡… 0 1.80 0 0 0 0 ## 5 120076 0 [乡… 0 0 0 6 0 0 ## 6 120080 0 [乡… 0 0 0 0 0 38 ## 7 120081 0 [乡… 0 0 0 4 0 0 ## 8 120084 0 [乡… 0 0 0 1.5 0 0 ## 9 120087 0 [乡… 0 0 0 3 0 0 ## 10 120088 0 [乡… 0 1.5 0 0 0 0 ## # ℹ 7,678 more rows 2.4.1 农业生产效率 a &lt;- cfps2010family %&gt;% select(fid,urban, starts_with(&quot;fk201_a&quot;),fk3,fk4,fe1)%&gt;% mutate(revenue = fk3-fk4)%&gt;% mutate_at(vars(starts_with(&quot;fk201_a&quot;)), funs(replace(., . &lt; 0, 0)))%&gt;% mutate_at(vars(&quot;revenue&quot;), funs(replace(., . &lt; 0, 0)))%&gt;% dplyr::filter(revenue&gt;0) ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. a ## # A tibble: 6,093 × 12 ## fid urban fk201_a_1 fk201_a_2 fk201_a_3 fk201_a_4 fk201_a_5 fk201_a_6 ## &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 110007 1 [城… 0 2.5 0 0 0 0 ## 2 120033 1 [城… 0 0 0 0.900 0 0 ## 3 120074 0 [乡… 0 1.80 0 0 0 0 ## 4 120075 0 [乡… 0 0 0 0 0 0 ## 5 120076 0 [乡… 0 0 0 6 0 0 ## 6 120081 0 [乡… 0 0 0 4 0 0 ## 7 120084 0 [乡… 0 0 0 1.5 0 0 ## 8 120087 0 [乡… 0 0 0 3 0 0 ## 9 120088 0 [乡… 0 1.5 0 0 0 0 ## 10 120090 0 [乡… 0 0 0 4.5 0 0 ## # ℹ 6,083 more rows ## # ℹ 4 more variables: fk3 &lt;dbl+lbl&gt;, fk4 &lt;dbl+lbl&gt;, fe1 &lt;dbl+lbl&gt;, ## # revenue &lt;dbl&gt; 一个有效的建议是在对原始数据进行操作时候，尽量保证原始数据的不变，再通过%&gt;%进行传导到新的数据框中。 我们计算农业生产效率的方法有很多这里主要参考的是一些主流的做法：将单位面积纯利润作为效率的衡量指标 a%&gt;% mutate(landsum = rowSums(.[2:7]))%&gt;% filter(landsum&gt;0)%&gt;% mutate(rates = revenue/landsum)-&gt;a1 a1 ## # A tibble: 6,048 × 14 ## fid urban fk201_a_1 fk201_a_2 fk201_a_3 fk201_a_4 fk201_a_5 fk201_a_6 ## &lt;dbl+lbl&gt; &lt;dbl+l&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 110007 1 [城… 0 2.5 0 0 0 0 ## 2 120033 1 [城… 0 0 0 0.900 0 0 ## 3 120074 0 [乡… 0 1.80 0 0 0 0 ## 4 120076 0 [乡… 0 0 0 6 0 0 ## 5 120081 0 [乡… 0 0 0 4 0 0 ## 6 120084 0 [乡… 0 0 0 1.5 0 0 ## 7 120087 0 [乡… 0 0 0 3 0 0 ## 8 120088 0 [乡… 0 1.5 0 0 0 0 ## 9 120090 0 [乡… 0 0 0 4.5 0 0 ## 10 120091 0 [乡… 0 0 0 4 0 0 ## # ℹ 6,038 more rows ## # ℹ 6 more variables: fk3 &lt;dbl+lbl&gt;, fk4 &lt;dbl+lbl&gt;, fe1 &lt;dbl+lbl&gt;, ## # revenue &lt;dbl&gt;, landsum &lt;dbl&gt;, rates &lt;dbl&gt; 2.4.2 流动人口 我们可以用外出打工在家庭人口中的占比来测算流动率。 library(conflicted) conflict_prefer(&#39;filter&#39;,&quot;dplyr&quot;) a1%&gt;% filter(fe1!=5)-&gt;a2 a2$fe1[a2$fe1==3] &lt;- 0 a2%&gt;% select(rates,fe1) ## # A tibble: 6,017 × 2 ## rates fe1 ## &lt;dbl&gt; &lt;dbl+lbl&gt; ## 1 371. 0 ## 2 7632. 0 ## 3 667. 0 ## 4 3000 1 [有] ## 5 6500 0 ## 6 2000 0 ## 7 6667. 0 ## 8 3333. 0 ## 9 4444. 0 ## 10 6250 0 ## # ℹ 6,007 more rows 2.5 模型建立 我们试图考察关于流动人口与农业生产效率之间的关系： reg &lt;- lm(data = a2,fe1~rates) summary(reg) ## ## Call: ## lm(formula = fe1 ~ rates, data = a2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.3873 -0.3869 -0.3862 0.6130 0.9042 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.873e-01 6.329e-03 61.2 &lt;2e-16 *** ## rates -8.330e-07 6.409e-07 -1.3 0.194 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4869 on 6015 degrees of freedom ## Multiple R-squared: 0.0002807, Adjusted R-squared: 0.0001145 ## F-statistic: 1.689 on 1 and 6015 DF, p-value: 0.1938 不过不显著。。。不过系数上看是一个较为合理的存在（效率上升，抑制外出）。对于一个想要看星星的reg monkey来说极其苦恼。我们可以考虑换一个变量：一篇2016年在《中国农村经济》的文章研究“非农就业、土地流转与农业生产效率变化”利用的是非农就业来考察劳动生产率（同样也是用单位土地的农产品收入来测算）就较为显著，主要的差别在于非农就业数量来测度，并非一个虚拟变量。 还有一个可能是在先前的数据处理中存在一定的问题，比如是否将未从事农业活动的家户过滤进来。 cfps2010family%&gt;% select(fid,familysize,starts_with(&quot;fu1_s&quot;))%&gt;% mutate_at(vars(starts_with(&quot;fu1_s&quot;)), funs(replace(., . &lt; 0, 0)))%&gt;% mutate_at(vars(starts_with(&quot;fu1_s&quot;)), funs(replace(., . &gt;=1, 1)))-&gt;b1 ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## ℹ Please use a list of either functions or lambdas: ## ## # Simple named list: list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: tibble::lst(mean, median) ## ## # Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 并不建议一次性将所有变换都做完，之后再检查是非常痛苦的。。。 b1%&gt;% mutate(mig = rowSums(.[3:14]))%&gt;% select(fid,familysize,mig)%&gt;% mutate(mig_rate = mig/familysize)%&gt;% filter(mig_rate&lt;=1&amp;mig_rate&gt;=0)-&gt;b2# 剔除异常值 barplot(table(b2$mig_rate)) dim(b2) ## [1] 14795 4 b3 &lt;- merge(a2,b2,by=&quot;fid&quot;) reg2 &lt;- lm(data = b3,mig_rate~rates) summary(reg2) ## ## Call: ## lm(formula = mig_rate ~ rates, data = b3) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.1249 -0.1248 -0.1247 0.1251 0.8760 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.249e-01 2.384e-03 52.40 &lt;2e-16 *** ## rates -2.029e-07 2.415e-07 -0.84 0.401 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1834 on 6015 degrees of freedom ## Multiple R-squared: 0.0001174, Adjusted R-squared: -4.887e-05 ## F-statistic: 0.706 on 1 and 6015 DF, p-value: 0.4008 p值比之前还更大了。。。上述提到的文章的核心解释变量是非农占家庭劳动力比例，但目前还不知咋构建的。。。想到了再补上去。 "],["文献复刻劳动力流动如何影响农户借贷.html", "3 文献复刻：《劳动力流动如何影响农户借贷》 3.1 文献回顾 3.2 数据处理 3.3 统计描述 3.4 模型设定", " 3 文献复刻：《劳动力流动如何影响农户借贷》 3.1 文献回顾 这篇文章主要发现劳动力流动导致农户借出的概率和金额显著增加。 核心的被解释变量为家庭是否有借给亲戚、朋友等的借出款项和为家庭人均借出金额的对数值。降低极端值影响，进行上下2%缩尾处理。 劳动力流动：是否有劳动力流动以及家庭劳动力流动人数。 控制变量： 3.2 数据处理 加载cfps2018数据: 3.3 统计描述 3.4 模型设定 "],["culture.html", "4 宗族文化 4.1 数据载入 4.2 可视化 4.3 地图 4.4 其他数据源 4.5 重新再利用", " 4 宗族文化 对于宗族文化的研究近些年一直是较为火热的研究热点(Cao, Xu, and Zhang 2022),(潘越 et al. 2019),(张心仪, 孙伟增, and 陈思宇 2021),(陈斌开 and 陈思宇 2018),(张川川 and 马光荣 2017),(Zhang 2020)和(Fan et al. 2023)。但对于宗族文化的测度方法又各具差异，比如 Zhang (2020), Cao, Xu, and Zhang (2022) 和 Fan et al. (2023) 都是使用上海古籍出版社的县地方族谱数据来测量宗族文化，张川川 and 马光荣 (2017) 使用的是CFPS的数据来测量；张心仪, 孙伟增, and 陈思宇 (2021) 使用的是地方的前三姓氏来作为度量，数据来源是2005年的1%人口抽样调查数据。数据质量上，直观感受是上海古籍出版社的数据会优于其他几个。 4.1 数据载入 如何在R中没有任何资源的前提下进行关于宗族文化的测度，我先试了做法最为简便的，城市的前三姓氏我翻遍了所有变量都没找到姓氏的变量；后面又看了下上海古籍出版社数据，数据量太大，估计需要爬虫等黑科技，遂又放弃，之后只有选择CFPS，之后也并不很顺利。 library(haven) cfps2010comm &lt;- read_dta(&quot;/Volumes/Expansion/micro-base-data/社区数据cfps/cfps2010comm_201906.dta&quot;) cfps2010comm%&gt;% select(cid,provcd,countyid,cyear,cmonth,ca3_s_6,ca3_s_7)-&gt;df1 head(df1) ## # A tibble: 6 × 7 ## cid provcd countyid cyear cmonth ca3_s_6 ca3_s_7 ## &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lb&gt; ## 1 13200 12 [天津市] 79 2010 10 -8 [不适用] … -8 [不… ## 2 13190 12 [天津市] 79 2010 10 9 [老年活动场所/… 13 [村/… ## 3 12780 14 [山西省] 69 2010 10 8 [教堂/清真寺] … 10 [敬… ## 4 21340 44 [广东省] 116 2010 10 9 [老年活动场所/… 13 [村/… ## 5 12260 23 [黑龙江省] 56 2010 9 -8 [不适用] … -8 [不… ## 6 21640 44 [广东省] 123 2010 10 7 [家族祠堂] … 11 [体… dim(df1) ## [1] 635 7 cfps2010comm$ca3_s_6[which(df1$ca3_s_6==-8)]=0 cfps2010comm$ca3_s_7[which(df1$ca3_s_7==-8)]=0 table(cfps2010comm$ca3_s_7) ## ## 0 2 7 8 9 10 11 12 13 14 15 ## 262 2 14 6 41 26 66 26 106 68 18 table(cfps2010comm$ca3_s_6) ## ## 0 2 3 5 6 7 8 9 10 11 12 13 14 15 ## 172 1 1 1 47 23 23 92 24 58 21 94 72 6 na.omit(df1) ## # A tibble: 635 × 7 ## cid provcd countyid cyear cmonth ca3_s_6 ca3_s_7 ## &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lb&gt; ## 1 13200 12 [天津市] 79 2010 10 -8 [不适用] … -8 [不… ## 2 13190 12 [天津市] 79 2010 10 9 [老年活动场所… 13 [村/… ## 3 12780 14 [山西省] 69 2010 10 8 [教堂/清真寺]… 10 [敬… ## 4 21340 44 [广东省] 116 2010 10 9 [老年活动场所… 13 [村/… ## 5 12260 23 [黑龙江省] 56 2010 9 -8 [不适用] … -8 [不… ## 6 21640 44 [广东省] 123 2010 10 7 [家族祠堂] … 11 [体… ## 7 21730 44 [广东省] 126 2010 10 -8 [不适用] … -8 [不… ## 8 22523 62 [甘肃省] 145 2010 9 -8 [不适用] … -8 [不… ## 9 10930 52 [贵州省] 24 2010 10 12 [儿童游乐场所… 13 [村/… ## 10 10100 34 [安徽省] 3 2010 10 6 [庙宇/道观] … 10 [敬… ## # ℹ 625 more rows dim(df1) ## [1] 635 7 根据社区问卷手册，我们可以指导 library(dplyr) cfps2010comm%&gt;% group_by(provcd)%&gt;% dplyr::summarise(x1=sum(ca3_s_6),x2=sum(ca3_s_7))-&gt;df2 df2 ## # A tibble: 25 × 3 ## provcd x1 x2 ## &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 [北京市] 27 14 ## 2 12 [天津市] 9 13 ## 3 13 [河北省] 216 178 ## 4 14 [山西省] 207 220 ## 5 21 [辽宁省] 525 511 ## 6 22 [吉林省] 97 112 ## 7 23 [黑龙江省] 159 155 ## 8 31 [上海市] 495 386 ## 9 32 [江苏省] 127 117 ## 10 33 [浙江省] 111 126 ## # ℹ 15 more rows 4.2 可视化 library(ggplot2) ggplot(df2)+ geom_point(aes(x=x1,y=x2))+ geom_smooth(method = &#39;lm&#39;,aes(x=x1,y=x2)) ## `geom_smooth()` using formula = &#39;y ~ x&#39; 图4.1: 祠堂与族谱 4.3 地图 将论文图表绘制在图上。 d &lt;- attributes(df2$provcd)$labels d &lt;- as.data.frame(d) d2 &lt;- rownames(d) d3 &lt;- cbind(d,d2) colnames(d3) &lt;- c(&quot;provcd&quot;,&quot;label&quot;) d4 &lt;- merge(df2,d3,by = &quot;provcd&quot;) d4 ## provcd x1 x2 label ## 1 11 27 14 北京市 ## 2 12 9 13 天津市 ## 3 13 216 178 河北省 ## 4 14 207 220 山西省 ## 5 21 525 511 辽宁省 ## 6 22 97 112 吉林省 ## 7 23 159 155 黑龙江省 ## 8 31 495 386 上海市 ## 9 32 127 117 江苏省 ## 10 33 111 126 浙江省 ## 11 34 123 113 安徽省 ## 12 35 47 63 福建省 ## 13 36 102 107 江西省 ## 14 37 220 125 山东省 ## 15 41 538 453 河南省 ## 16 42 76 90 湖北省 ## 17 43 190 147 湖南省 ## 18 44 493 566 广东省 ## 19 45 107 35 广西壮族自治区 ## 20 50 66 59 重庆市 ## 21 51 155 149 四川省 ## 22 52 88 71 贵州省 ## 23 53 147 141 云南省 ## 24 61 73 58 陕西省 ## 25 62 517 408 甘肃省 json数据来源于阿里 DataV 数据可视化平台，能够在多个行政层级绘制中国地图。 library(echarts4r.maps) library(echarts4r) colnames(d4) &lt;- c(&quot;provcd&quot;,&quot;value1&quot;,&quot;value2&quot;,&quot;region&quot;) china_map &lt;- jsonlite::read_json(&quot;rep.json&quot;) d4 %&gt;% e_charts(region)%&gt;% e_map_register(&quot;China2&quot;, china_map) %&gt;% e_map(value1, map = &quot;China2&quot;) %&gt;% e_visual_map(value1) d4 %&gt;% e_charts(region)%&gt;% e_map_register(&quot;China2&quot;, china_map) %&gt;% e_map(value2, map = &quot;China2&quot;) %&gt;% e_visual_map(value2) 上面的数据还是挺让人吃惊的，一般会认为宗族文化会在南方更为发达，包括修建祠堂上，我们通过图 4.1 中知道祠堂与家谱是基本上在省层面是正相关的，但地域上呈现了较大的差异。可能是与抽样方法有关，需要进一步的处理。 4.4 其他数据源 目前学界用的较为广泛的是通过上海家族族谱来测算宗族文化，也就是看一个地方的族谱的密度来作为宗族文化的代理变量，代表性学者有浙大的张川川老师，他目前发表的关于宗族文化的论文有(Cao, Xu, and Zhang 2022), (Zhang 2020), (张川川 and 马光荣 2017)。 很巧，他和合作者Yiqin Xu和博士生曹家瑞在JDE刊发的论文有replicate file(可直接下载) 但图中的图是使用ArcGIS来实现的，这里试图通过R来进行复刻。 clan_gbook &lt;- read_dta(&quot;/Users/a182501/stata-replicat/rep-jde-2021-cao-xu-zhang/datafiles/gbooks_byyear.dta&quot;) head(clan_gbook) ## # A tibble: 6 × 2 ## year year_imp ## &lt;dbl&gt; &lt;dbl&gt; ## 1 970 970 ## 2 1430 1430 ## 3 1800 1800 ## 4 1880 1880 ## 5 1890 1890 ## 6 1900 1900 p &lt;- clan_gbook%&gt;% dplyr::filter(year&lt;=2010&amp;year&gt;=1400)%&gt;% ggplot()+ geom_histogram(aes(year_imp),binwidth = 1) p+geom_vline(aes(xintercept=1950), colour=&quot;#BB0000&quot;,size = 0.2)+ geom_vline(aes(xintercept=1980), colour=&quot;#BB0000&quot;,size = 0.2)+xlab(&quot;Year&quot;)+ylab(&quot;Frequency&quot;) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 在统计上的大小与原作者给出的频率有一定的差异，不过形状是相同的。 library(mapchina) library(sysfonts) library(showtextdb) library(showtext) library(sf) ## Linking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE library(haven) clan_disr &lt;- read_dta(&quot;/Users/a182501/stata-replicat/rep-jde-2021-cao-xu-zhang/datafiles/clan_distr.dta&quot;) arrange(clan_disr,provcd) ## # A tibble: 1,145 × 3 ## provcd lnzupunum50 countycode ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 13 0.0421 1 ## 2 13 0 3 ## 3 13 0 9 ## 4 13 0 18 ## 5 13 0.105 23 ## 6 13 0.203 26 ## 7 13 0.310 42 ## 8 13 0.160 44 ## 9 13 0.0281 48 ## 10 13 0 70 ## # ℹ 1,135 more rows head(china) ## Simple feature collection with 6 features and 13 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 115.4248 ymin: 39.44473 xmax: 116.8805 ymax: 41.05936 ## Geodetic CRS: WGS 84 ## # A tibble: 6 × 14 ## Code_County Code_Perfecture Code_Province Name_Province Name_Perfecture ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 110101 1101 11 北京市 &lt;NA&gt; ## 2 110102 1101 11 北京市 &lt;NA&gt; ## 3 110114 1101 11 北京市 &lt;NA&gt; ## 4 110115 1101 11 北京市 &lt;NA&gt; ## 5 110111 1101 11 北京市 &lt;NA&gt; ## 6 110116 1101 11 北京市 &lt;NA&gt; ## # ℹ 9 more variables: Name_County &lt;chr&gt;, Pinyin &lt;chr&gt;, Pop_2000 &lt;dbl&gt;, ## # Pop_2010 &lt;dbl&gt;, Pop_2017 &lt;dbl&gt;, Pop_2018 &lt;dbl&gt;, Area &lt;dbl&gt;, Density &lt;dbl&gt;, ## # geometry &lt;MULTIPOLYGON [°]&gt; 4.5 重新再利用 尽管我们没有关于县级层面的宏观经济等控制变量，但我们可以将获得的数据反向匹配给到个人，看宗族祠堂对于个人的影响是如何呈现的。 我们这里选择使用cfps2014年的数据，处理方法基本上与2010年一致。 cfps2014comm &lt;- read_dta(&quot;/Users/a182501/project_set/data/cfps/2014/cfps2014comm_201906.dta&quot;) cfps2014comm$ca3_s_6[which(cfps2014comm$ca3_s_6==-8)] &lt;- 0 cfps2014comm$ca3_s_7[which(cfps2014comm$ca3_s_7==-8)] &lt;- 0 #View(cfps2014comm)随时观察变量 cfps2014comm%&gt;% select(cid14,cid10,ca3_s_6,ca3_s_7)-&gt;comm14 head(comm14) ## # A tibble: 6 × 4 ## cid14 cid10 ca3_s_6 ca3_s_7 ## &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; ## 1 118100 11810 0 0 ## 2 118200 11820 0 0 ## 3 212300 21230 7 [通公路] 12 [实施村/居直接选举] ## 4 209100 20910 0 0 ## 5 118300 11830 0 0 ## 6 118400 11840 0 0 调用家户数据 famconf14 &lt;- read_dta(&quot;/Users/a182501/project_set/data/cfps/2014/cfps2014famconf_170630.dta&quot;) head(famconf14) ## # A tibble: 6 × 307 ## fid14 fid12 fid10 provcd14 countyid14 cid14 urban14 pid ## &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lbl&gt; &lt;dbl+lb&gt; &lt;dbl+lbl&gt; &lt;dbl+&gt; &lt;dbl+l&gt; &lt;dbl+&gt; ## 1 100051 -8 [不适… -8 [不… 11 [北… 45 624942 1 [城… 1.00e8 ## 2 100051 -8 [不适… -8 [不… 11 [北… 45 624942 1 [城… 1.00e8 ## 3 100051 110043 … 110043 … 11 [北… 45 624942 1 [城… 1.10e8 ## 4 100125 110147 … 110147 … 11 [北… 170 564346 1 [城… 1.10e8 ## 5 100160 120009 … 120009 … 12 [天… 79 131700 1 [城… 1.20e8 ## 6 100286 130005 … 130005 … 13 [河… 237 161210 1 [城… 1.30e8 ## # ℹ 299 more variables: code_a_p &lt;dbl+lbl&gt;, tb2_a_p &lt;dbl+lbl&gt;, ## # tb1y_a_p &lt;dbl+lbl&gt;, tb1m_a_p &lt;dbl+lbl&gt;, tb1a_a_p &lt;dbl+lbl&gt;, ## # tb3_a14_p &lt;dbl+lbl&gt;, tb4_a14_p &lt;dbl+lbl&gt;, alive_a14_p &lt;dbl+lbl&gt;, ## # ta4y_a14_p &lt;dbl+lbl&gt;, ta4m_a14_p &lt;dbl+lbl&gt;, ta401_a14_p &lt;chr&gt;, ## # qa301_a14_p &lt;dbl+lbl&gt;, qa302_a14_p &lt;dbl+lbl&gt;, tb6_a14_p &lt;dbl+lbl&gt;, ## # tb601_a14_p &lt;dbl+lbl&gt;, co_a14_p &lt;dbl+lbl&gt;, outpers_where14_p &lt;dbl+lbl&gt;, ## # tb602acode_a14_p &lt;dbl+lbl&gt;, cfps2014_interv_p &lt;dbl+lbl&gt;, … 使用左连接left_join以保留我们的家户信息，用村居样本代码cid14来进行匹配。 library(visdat) famcon14_clan &lt;- left_join(famconf14,comm14,by=&quot;cid14&quot;) dim(famcon14_clan) ## [1] 57734 310 dim(famconf14) ## [1] 57734 307 #View(famcon14_clan) famcon14_clan%&gt;% select(cid14,cid10,ca3_s_6,ca3_s_7,tb2_a_p,tb1y_a_p,cfps2014_interv_p,tb4_a14_p,urban14,tb4_a14_f)%&gt;% dplyr::filter(urban14==0)%&gt;% dplyr::filter(tb4_a14_p!=-8)%&gt;% dplyr::filter(tb4_a14_p!=-9)%&gt;% dplyr::filter(!is.na(cid10))%&gt;% mutate(age=2014-tb1y_a_p)%&gt;% mutate(eduyear = case_when( tb4_a14_p==8 ~ 23, tb4_a14_p==7 ~ 19, tb4_a14_p==6 ~ 16, tb4_a14_p==5 ~ 15, tb4_a14_p==4 ~ 12, tb4_a14_p==3 ~ 9, tb4_a14_p==2 ~ 6, tb4_a14_p==1 ~ 0 ))%&gt;% mutate(temple_dummy = case_when( ca3_s_6==0~0, ca3_s_6&gt;0~1 ))%&gt;% mutate(genealogy_dummy = case_when( ca3_s_7 == 0~0, ca3_s_7 &gt; 0~1 ))%&gt;% mutate(eduyear_fa = case_when( tb4_a14_f==8 ~ 23, tb4_a14_f==7 ~ 19, tb4_a14_f==6 ~ 16, tb4_a14_f==5 ~ 15, tb4_a14_f==4 ~ 12, tb4_a14_f==3 ~ 9, tb4_a14_f==2 ~ 6, tb4_a14_f==1 ~ 0 ))-&gt; facon14_clan_clean dim(facon14_clan_clean) ## [1] 29190 15 sum(table(facon14_clan_clean$eduyear)) ## [1] 27780 table(facon14_clan_clean$eduyear_fa) ## ## 0 6 9 12 15 16 19 23 ## 9139 6435 5176 1850 284 109 4 1 table(facon14_clan_clean$temple_dummy) ## ## 0 1 ## 28033 1157 colnames(facon14_clan_clean) ## [1] &quot;cid14&quot; &quot;cid10&quot; &quot;ca3_s_6&quot; ## [4] &quot;ca3_s_7&quot; &quot;tb2_a_p&quot; &quot;tb1y_a_p&quot; ## [7] &quot;cfps2014_interv_p&quot; &quot;tb4_a14_p&quot; &quot;urban14&quot; ## [10] &quot;tb4_a14_f&quot; &quot;age&quot; &quot;eduyear&quot; ## [13] &quot;temple_dummy&quot; &quot;genealogy_dummy&quot; &quot;eduyear_fa&quot; reg_temple &lt;- lm(data = facon14_clan_clean,eduyear~temple_dummy+age+tb2_a_p)# 控制母亲的受教育水平/父亲的受教育水平 summary(reg_temple) ## ## Call: ## lm(formula = eduyear ~ temple_dummy + age + tb2_a_p, data = facon14_clan_clean) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9472 -4.8059 0.3229 3.3196 14.2842 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.6291262 0.0459993 100.635 &lt;2e-16 *** ## temple_dummy -0.2351321 0.1448925 -1.623 0.105 ## age 0.0033346 0.0003746 8.903 &lt;2e-16 *** ## tb2_a_p 0.9879641 0.0534791 18.474 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.714 on 27776 degrees of freedom ## (1410 observations deleted due to missingness) ## Multiple R-squared: 0.0123, Adjusted R-squared: 0.0122 ## F-statistic: 115.3 on 3 and 27776 DF, p-value: &lt; 2.2e-16 reg_genealogy &lt;- lm(data = facon14_clan_clean,eduyear~genealogy_dummy+age+tb2_a_p) summary(reg_genealogy) ## ## Call: ## lm(formula = eduyear ~ genealogy_dummy + age + tb2_a_p, data = facon14_clan_clean) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9464 -4.8052 0.3202 3.3202 14.2848 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.6285474 0.0459432 100.745 &lt;2e-16 *** ## genealogy_dummy -0.2627547 0.1583737 -1.659 0.0971 . ## age 0.0033325 0.0003746 8.897 &lt;2e-16 *** ## tb2_a_p 0.9879593 0.0534790 18.474 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.714 on 27776 degrees of freedom ## (1410 observations deleted due to missingness) ## Multiple R-squared: 0.01231, Adjusted R-squared: 0.0122 ## F-statistic: 115.4 on 3 and 27776 DF, p-value: &lt; 2.2e-16 还是对族谱的回归会微弱显著，不过都是负的系数，和一些学者之前研究的结论有一些差别，但可能是在这里控制变量控制的不够，可能存在内生性问题，比如遗漏一些关键的控制变量，受访者的智力水平、家庭规模，父亲的政治背景、教育理念、文化资本等。 不过个人认为这里可以使用族谱的数量，并不需要将其转变为虚拟变量。 reg_genealogy_cont &lt;- lm(data = facon14_clan_clean,eduyear~ca3_s_7+age+tb2_a_p) summary(reg_genealogy_cont) ## ## Call: ## lm(formula = eduyear ~ ca3_s_7 + age + tb2_a_p, data = facon14_clan_clean) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.9476 -4.8062 0.3191 3.3191 14.2838 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.6294935 0.0459205 100.815 &lt;2e-16 *** ## ca3_s_7 -0.0323995 0.0169295 -1.914 0.0557 . ## age 0.0033338 0.0003746 8.901 &lt;2e-16 *** ## tb2_a_p 0.9880811 0.0534782 18.476 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.713 on 27776 degrees of freedom ## (1410 observations deleted due to missingness) ## Multiple R-squared: 0.01234, Adjusted R-squared: 0.01223 ## F-statistic: 115.7 on 3 and 27776 DF, p-value: &lt; 2.2e-16 参考文献 "],["charls.html", "5 CHARLS 5.1 数据导入", " 5 CHARLS CHARLS是中国中老年人调查数据，由北大发起的关于中国中老年人的社会调查。 5.1 数据导入 library(haven) getwd() ## [1] &quot;/Users/a182501/project_set/rrp&quot; charls2018cogn &lt;- read_dta(&quot;/Volumes/Expansion/micro-base-data/charls/2018/Cognition.dta&quot;) head(charls2018cogn) ## # A tibble: 6 × 219 ## ID householdID communityID dc001_w4 dc002_w4 dc003_w4 dc005_w4 dc006_w4 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; ## 1 09400411… 0940041130 0940041 1 [1 Co… 1 [1 Co… 5 [5 Er… 1 [1 Co… 1 [1 Co… ## 2 09400411… 0940041110 0940041 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… ## 3 09400411… 0940041110 0940041 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… ## 4 09400411… 0940041120 0940041 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… ## 5 09400411… 0940041180 0940041 1 [1 Co… 1 [1 Co… 5 [5 Er… 1 [1 Co… 1 [1 Co… ## 6 09400411… 0940041180 0940041 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… 1 [1 Co… ## # ℹ 211 more variables: dc007_w4 &lt;dbl+lbl&gt;, dc008_w4 &lt;dbl+lbl&gt;, ## # dc009_w4 &lt;dbl+lbl&gt;, dc010_w4 &lt;dbl+lbl&gt;, dc012_w4 &lt;dbl+lbl&gt;, ## # dc004 &lt;dbl+lbl&gt;, dc013_w4_1_s1 &lt;dbl+lbl&gt;, dc013_w4_1_s2 &lt;dbl+lbl&gt;, ## # dc013_w4_1_s3 &lt;dbl+lbl&gt;, dc013_w4_1_s4 &lt;dbl+lbl&gt;, dc013_w4_1_s97 &lt;dbl+lbl&gt;, ## # dc013_w4_2_s1 &lt;dbl+lbl&gt;, dc013_w4_2_s2 &lt;dbl+lbl&gt;, dc013_w4_2_s3 &lt;dbl+lbl&gt;, ## # dc013_w4_2_s4 &lt;dbl+lbl&gt;, dc013_w4_2_s97 &lt;dbl+lbl&gt;, dc013_w4_3_s1 &lt;dbl+lbl&gt;, ## # dc013_w4_3_s2 &lt;dbl+lbl&gt;, dc013_w4_3_s3 &lt;dbl+lbl&gt;, … library(purrr) get_var_label &lt;- function(dta) { labels &lt;- map(dta, function(x) attr(x, &quot;label&quot;)) data_frame( name = names(labels), label = as.character(labels) ) } #View(charls2018cogn) charls2018cogn%&gt;% select(starts_with(&quot;dc014&quot;))%&gt;% get_var_label() ## Warning: `data_frame()` was deprecated in tibble 1.1.0. ## ℹ Please use `tibble()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## # A tibble: 11 × 2 ## name label ## &lt;chr&gt; &lt;chr&gt; ## 1 dc014_w4_1 Reason for Missing from 100-7 ## 2 dc014_w4_1_1 Specific Result from 100-7 ## 3 dc014_w4_2 Reason for Missing from dc014_w4_1-7 ## 4 dc014_w4_2_1 Specific Result from dc014_w4_2-7 ## 5 dc014_w4_3 Reason for Missing from dc014_w4_2-7 ## 6 dc014_w4_3_1 Specific Result from dc014_w4_3-7 ## 7 dc014_w4_4 Reason for Missing from dc014_w4_3-7 ## 8 dc014_w4_4_1 Specific Result from dc014_w4_4-7 ## 9 dc014_w4_5 Reason for Missing from dc014_w4_4-7 ## 10 dc014_w4_5_1 Specific Result from dc014_w4_5-7 ## 11 dc014 I Felt Fearful "],["文献复刻新型农村社会养老保险政策效果评估.html", "6 文献复刻：《新型农村社会养老保险政策效果评估》 6.1 数据导入", " 6 文献复刻：《新型农村社会养老保险政策效果评估》 这篇文章是使用断点回归和DID的方法， 实际上是利用领取养老金的年龄规则，只有年满60周岁的参保人员才能领取 因变量：家户总收入、家户人均收入、个人收入、个人非劳动收入； 6.1 数据导入 "],["chfs.html", "7 CHFS 7.1 数据读取 7.2 构建变量", " 7 CHFS CHFS是西南财经大学组织的中国家庭金融调查。中国家 庭金融调查采用三阶段、分层、与人口规模成比例(PPS)的抽样方法，通过科学抽样、现 代调查技术和调查管理手段，收集中国家庭金融微观信息，为国内外研究者提供研究 中国家庭金融问题的高质量微观数据。 CHFS样本覆盖全国29个省，262个县，总共包含28000多户家庭的资产负债、收入与支出、保险与保障，家庭人口特征及就业等方面详细信息的大型微观数据。 7.1 数据读取 library(haven) library(purrr) get_var_label &lt;- function(dta) { labels &lt;- map(dta, function(x) attr(x, &quot;label&quot;)) tibble( name = names(labels), label = as.character(labels) ) } 7.2 构建变量 7.2.1 社会互动 Du et al. (2014) 社会互动相关的礼金支出、外出就餐支出、娱乐支出、通讯支出、交通支出、旅游探亲支出、兄弟姐妹数量、与父母通话次数 8 个变量。 7.2.2 金融知识 在CHFS中第五部分就是关于金融知识、底层治理与主观评价。 chfs_hh2013 &lt;- read_dta(&quot;/Volumes/Expansion/micro-base-data/chfs/CHFS_2013/chfs2013_hh_20191120_version14.dta&quot;) chfs_hh2013%&gt;%get_var_label() ## # A tibble: 2,184 × 2 ## name label ## &lt;chr&gt; &lt;chr&gt; ## 1 hhid_2011 household id in 2011 ## 2 hhid_2013 household id in 2013 ## 3 a2000a 居住在一起家庭成员个数 ## 4 a2000b 外出家庭成员个数 ## 5 a1001 地址是否正确 ## 6 a1002 是否居民住宅 ## 7 a1003 住宅户数 ## 8 a1007 主要经济活动 ## 9 a1008 是否常住本市 ## 10 a1009 有无外国国籍 ## # ℹ 2,174 more rows dim(chfs_hh2013) ## [1] 28141 2184 chfs_hh2013%&gt;% select(starts_with(&quot;a400&quot;))-&gt;df2_a df2_na &lt;- na.omit(df2_a) dim(df2_na) ## [1] 26922 7 df2_na%&gt;% get_var_label() ## # A tibble: 7 × 2 ## name label ## &lt;chr&gt; &lt;chr&gt; ## 1 a4002a 对经济、金融信息的关注度 ## 2 a4002b 上学期间是否上过经济、金融课程 ## 3 a4003 投资风险态度 ## 4 a4004a 100元存5年的本息和 ## 5 a4005a 100元存款一年后的购买力 ## 6 a4006a 100%得4000和50%得10000的偏好 ## 7 a4007aa 单买一只股票和买一只股票基金的风险 参考 张号栋 and 尹志超 (2016) 的做法： df2_na%&gt;% mutate(fa1=case_when( a4002a%in%c(1,2,3)~1, a4002a%in%c(4,5)~0 ))%&gt;% mutate(fa2 = case_when( a4002b==1~1, a4002b==2~0 ))%&gt;% mutate(fa3 = case_when( a4007aa==1~1, a4007aa!=1~0 ))%&gt;% mutate(fa4=case_when( a4004a==2~1, a4004a!=2~0 ))%&gt;% mutate(fa5=case_when( a4006a==2~1, a4006a==1~0 ))%&gt;% mutate(fa6=case_when( a4005a==1~1, a4005a!=1~0 ))%&gt;% select(starts_with(&quot;fa&quot;))-&gt;df_fa library(visdat) df_fa %&gt;% vis_dat() mean_fa &lt;- map_dbl(df_fa,mean) mean_fa ## fa1 fa2 fa3 fa4 fa5 fa6 ## 0.37118342 0.08160612 0.30740658 0.15474333 0.26799643 0.16072357 得到的均值水平会比原文章都普遍较高一些。但因素5的偏差较大。（但本人又认为这个变量不太好，更像是一个风险测试的问题，与受访者的风险偏好有关，并没有一个所谓正确的答案） 1-mean_fa[5] ## fa5 ## 0.7320036 7.2.2.1 因子转换 library(psych) #KMO和Bartlette检验所需包 ## ## Attaching package: &#39;psych&#39; ## The following objects are masked from &#39;package:ggplot2&#39;: ## ## %+%, alpha KMO(df_fa) ## Kaiser-Meyer-Olkin factor adequacy ## Call: KMO(r = df_fa) ## Overall MSA = 0.65 ## MSA for each item = ## fa1 fa2 fa3 fa4 fa5 fa6 ## 0.64 0.64 0.66 0.69 0.70 0.70 都大于0.6，勉强适合。 bartlett.test(df_fa) ## ## Bartlett test of homogeneity of variances ## ## data: df_fa ## Bartlett&#39;s K-squared = 10938, df = 5, p-value &lt; 2.2e-16 p值非常小，也验证可以做因子。 corr=cor(df_fa) eig=eigen(corr) (ccx=(eig$va)/sum(eig$va)) #贡献率 ## [1] 0.2677825 0.1643641 0.1626099 0.1501068 0.1306874 0.1244494 (cx=cumsum(eig$va)/sum(eig$va)) #累计方差贡献率 ## [1] 0.2677825 0.4321466 0.5947564 0.7448632 0.8755506 1.0000000 fit &lt;- factanal(df_fa, 3, rotation=&quot;promax&quot;) # 第2个参数是提取的因子个数 print(fit, digits=2, sort=TRUE) # 输出结果 ## ## Call: ## factanal(x = df_fa, factors = 3, rotation = &quot;promax&quot;) ## ## Uniquenesses: ## fa1 fa2 fa3 fa4 fa5 fa6 ## 0.74 0.75 0.80 0.00 0.95 0.92 ## ## Loadings: ## Factor1 Factor2 Factor3 ## fa4 1.00 ## fa1 0.38 0.18 ## fa2 0.49 ## fa3 0.34 0.15 ## fa5 0.22 ## fa6 0.30 ## ## Factor1 Factor2 Factor3 ## SS loadings 0.99 0.51 0.20 ## Proportion Var 0.17 0.08 0.03 ## Cumulative Var 0.17 0.25 0.28 ## ## Factor Correlations: ## Factor1 Factor2 Factor3 ## Factor1 1.00 0.17 0.23 ## Factor2 0.17 1.00 0.58 ## Factor3 0.23 0.58 1.00 ## ## The degrees of freedom for the model is 0 and the fit was 0 7.2.3 金融排斥 “是否有金融账户”来作为是否是存在金融排斥的代理变量。 chfs_hh2013 %&gt;% select(d1101)%&gt;% dplyr::filter(!is.na(d1101))%&gt;% mutate(cur= case_when( d1101 == 1~1, d1101 == 2~0 ))-&gt;df3 mean(df3$cur) ## [1] 0.595189 也就是有人民币活期存款账户的有59.51%。但根据文章中的定义：还需要对其余的金融账户进行筛选，通过逻辑运算实现。 参考文献 "],["其他来源数据.html", "8 其他来源数据 8.1 方言数据 8.2 夜间灯光数据 8.3 政治数据", " 8 其他来源数据 其他数据来源包括相关领域内的学者对于在其文章中的数据以及公开的数据集中的数据。 比如哈佛大学的王教授收集了关于地方的数据 8.1 方言数据 library(mapchina) library(sysfonts) library(showtextdb) library(showtext) library(tidyverse) library(sf) 徐现祥老师在其个人网站上公开了其地方的方言数据，也就是 连享会gitee仓库有相关数据集合 library(haven) df &lt;- read_dta(&quot;/Volumes/Expansion/micro-base-data/China_dialect_diversity_index.dta&quot;) head(df) ## # A tibble: 6 × 3 ## city diversity1 diversity2 ## &lt;dbl+lbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 256 [阿勒泰地区] 0.650 2 ## 2 75 [安康市] 0.475 2 ## 3 74 [安庆市] 0.477 2 ## 4 77 [安顺市] 0.570 1 ## 5 76 [安阳市] 0.463 2 ## 6 261 [鞍山市] 0.428 3 lab &lt;- attributes(df$city)$labels lab &lt;- as.data.frame(lab) lab_name &lt;- rownames(lab) lab_df &lt;- cbind(lab,lab_name) colnames(lab_df) &lt;- c(&quot;city&quot;,&quot;city_name&quot;) df_lab &lt;- merge(df,lab_df,by = &quot;city&quot;) head(df_lab) ## city diversity1 diversity2 city_name ## 1 1 0.1071 1 七台河市 ## 2 2 0.5067 1 三亚市 ## 3 3 0.4763 2 三门峽市 ## 4 4 0.0126 1 上海市 ## 5 5 0.5792 4 上饶市 ## 6 6 0.0603 1 东莞市 我们这里使用的是mapchina包，能够在不同的行政层级上绘制中国区划地图。 sf_use_s2(FALSE) df1 &lt;- china%&gt;% dplyr::filter(is.na(china$Name_Perfecture))%&gt;% mutate(Name_Perfecture=Name_Province) df2 &lt;- china%&gt;% dplyr::filter(is.na(china$Name_Perfecture)==F) df3 &lt;- rbind(df1,df2) dim(df3) ## [1] 2901 14 dim(china) ## [1] 2901 14 df3_perf &lt;- df3 %&gt;% group_by(Name_Perfecture) %&gt;% summarise(geometry = st_union(geometry)) colnames(df_lab) &lt;- c(&quot;city&quot;,&quot;d1&quot;,&quot;d2&quot;,&quot;Name_Perfecture&quot;) df_all &lt;- left_join(df3_perf,df_lab,by = &quot;Name_Perfecture&quot;) 地区的不同方言类别： ggplot(data = df_all) + geom_sf(aes(fill = d2)) + scale_fill_distiller(palette = &quot;YlOrRd&quot;)+ theme_bw() 地方方言的多样性指数： ggplot(data = df_all) + geom_sf(aes(fill = d1)) + scale_fill_distiller(palette = &quot;YlOrRd&quot;)+ theme_bw() 8.2 夜间灯光数据 我们想要复刻一下上面的案例，但缺乏城市GDP数据，但我又懒于去用学校wind或数据网站上爬。就想要看下国内有没有可以用的API可以获得相关数据。 8.2.1 获取方法 nightlight data 8.2.2 API 8.3 政治数据 "],["论文复刻climate-risks-and-market-efficiency.html", "9 论文复刻Climate risks and market efficiency 9.1 Data", " 9 论文复刻Climate risks and market efficiency Hong, Li, and Xu (2019) 这篇文章发表在Journal of Econometrics 上，主要讲的是国家气候风险上升，使得国家的粮食价格得到下降，但并没有反映在实际的价格上，验证了在粮食市场上存在非完全有效市场。 9.1 Data 数据来自于Harrison Hong的homepage 同样也有do file。 library(haven) library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo pdsi &lt;- read.csv(&quot;/Volumes/Expansion/micro-base-data/honglixu_2019/PDSI_world.csv&quot;) PDSI数据也可以从NOAA中获取，不过需要注册，经过审核之后就可以免费下载。 library(xts) ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## ## ################################### WARNING ################################### ## # We noticed you have dplyr installed. The dplyr lag() function breaks how # ## # base R&#39;s lag() function is supposed to work, which breaks lag(my_xts). # ## # # ## # Calls to lag(my_xts) that you enter or source() into this session won&#39;t # ## # work correctly. # ## # # ## # All package code is unaffected because it is protected by the R namespace # ## # mechanism. # ## # # ## # Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning. # ## # # ## # You can use stats::lag() to make sure you&#39;re not using dplyr::lag(), or you # ## # can add conflictRules(&#39;dplyr&#39;, exclude = &#39;lag&#39;) to your .Rprofile to stop # ## # dplyr from breaking base R&#39;s lag() function. # ## ################################### WARNING ################################### ## ## Attaching package: &#39;xts&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## first, last pdsi%&gt;% select(Date,Peru)%&gt;% dplyr::filter(Peru!=-999)-&gt;pdsi_peru pdsi_peru_ts &lt;- as.xts(pdsi_peru$Peru,as.Date(pdsi_peru$Date)) plot(pdsi_peru_ts) pdsi%&gt;% select(Date,New_Zealand)%&gt;% dplyr::filter(New_Zealand!=-999)-&gt;pdsi_nz pdsi_nz_ts &lt;- as.xts(pdsi_nz$New_Zealand,as.Date(pdsi_nz$Date)) plot(pdsi_nz_ts) 从数据中，我们可以看出有一定的趋势，尽管可能并不明显。 我们就可以从试图去构建一个含有线性时间固定趋势的模型。 tt &lt;- seq(length(pdsi_nz_ts)) reslm &lt;- lm(c(pdsi_nz_ts) ~ tt); summary(reslm) ## ## Call: ## lm(formula = c(pdsi_nz_ts) ~ tt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.9739 -1.5492 -0.1941 1.7932 5.8579 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.2921454 0.1212183 -10.660 &lt; 2e-16 *** ## tt 0.0006777 0.0001521 4.457 8.98e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.25 on 1378 degrees of freedom ## Multiple R-squared: 0.01421, Adjusted R-squared: 0.0135 ## F-statistic: 19.87 on 1 and 1378 DF, p-value: 8.982e-06 plot(tt, pdsi_nz_ts, type=&quot;l&quot;, xlab=&quot;Time&quot;, ylab=&quot;PDSI in New Zealand&quot;, main=&quot;Fixed Linear Trend&quot;) abline(reslm, lwd=1.5, col=&quot;red&quot;) 但固定趋势的模型可能并不精确，比如上述的线性固定趋势模型的R方就较小，拟合性较差。因此在文章中就使用每次的来\\(b_{it}\\)来构建。 第一个回归方程就是想要先构建一个趋势(\\(Trend_{it}\\))变量，通过AR(1)模型来实现 文章中是这样说的： 后面的数据都是用1984-2019年的。 end_date &lt;-which(pdsi$Date==&quot;2014/12/1&quot;) begin_date &lt;- which(pdsi$Date==&quot;1984/1/1&quot;) pdsi_1984 &lt;- pdsi[begin_date:end_date,] dim(pdsi_1984) ## [1] 372 45 #12*(2014-1984)+12 \\[\\begin{equation} PDSI_{i,t} = a_i + b_{i}t+c_iPDSI_{i,t−1}+\\epsilon_{i,t} \\tag{1} \\label{eq:1} \\end{equation}\\] 其中的\\(b_{i}\\)就是希望捕捉的趋势变量，每到一个\\(m\\)进行一次rolling，可以获得从1900（或者更早）到m时期的\\(Trend_{i,m}\\) 作者还将滞后2，3期的回归附录放在Dropbox pdsi%&gt;% select(Date,Australia)%&gt;% dplyr::filter(Australia!=-999)-&gt;pdsi_au head(pdsi_au) ## Date Australia ## 1 1900/1/1 -3.31573868 ## 2 1900/2/1 -4.25730371 ## 3 1900/3/1 -0.01355382 ## 4 1900/4/1 1.12726247 ## 5 1900/5/1 2.32717538 ## 6 1900/6/1 2.16344261 au_ts &lt;- ts(pdsi_au$Australia, start=c(1900,1), frequency=12,end = c(1984,12)) acf(au_ts, main=&quot;&quot;) ar(au_ts, method=&quot;mle&quot;) ## ## Call: ## ar(x = au_ts, method = &quot;mle&quot;) ## ## Coefficients: ## 1 ## 0.875 ## ## Order selected 1 sigma^2 estimated as 0.9599 对于澳大利亚的数据给出的AR(1)模型。 \\(\\ref{eq:1}\\) 的可以转换为\\(Y_t = a + b*t + \\epsilon_t\\), where \\(\\epsilon_t = \\phi\\epsilon_{t-1}+\\gamma_t\\) a AR(1) process, where \\(\\epsilon_t\\) is a white noise. 数据中有31个国家，也就是要做31次回归。。。太累了。 参考文献 "],["文献复刻the-long-term-effects-of-africas-slave-trades.html", "10 文献复刻：The Long-term Effects of Africa’s Slave Trades 10.1 文献回顾 10.2 数据来源 10.3 计算最近的贸易距离", " 10 文献复刻：The Long-term Effects of Africa’s Slave Trades Nunn (2008) 这篇文献可称为是在学习IV时候的经典文献，2008年发表在QJE。 10.1 文献回顾 10.2 数据来源 if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman pacman::p_load( sf, # vector data operations tidyverse, # data wrangling units, rmapshaper, lwgeom, tictoc, haven ) #--- coast line ---# coast &lt;- sf::st_read(here::here(&quot;/Users/a182501/project_set/data/nunn_2008/input/10m-coastline/10m_coastline.shp&quot;)) %&gt;% st_transform(3857) ## Reading layer `10m_coastline&#39; from data source ## `/Users/a182501/project_set/data/nunn_2008/input/10m-coastline/10m_coastline.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 4177 features and 3 fields ## Geometry type: MULTILINESTRING ## Dimension: XY ## Bounding box: xmin: -180 ymin: -85.22198 xmax: 180 ymax: 83.6341 ## Geodetic CRS: WGS 84 #--- African countries ---# countries &lt;- sf::st_read(here::here(&quot;/Users/a182501/project_set/data/nunn_2008/input/gadm36_africa/gadm36_africa.shp&quot;)) %&gt;% st_transform(3857) ## Reading layer `gadm36_africa&#39; from data source ## `/Users/a182501/project_set/data/nunn_2008/input/gadm36_africa/gadm36_africa.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 54 features and 2 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -25.3618 ymin: -34.83514 xmax: 63.50347 ymax: 37.55986 ## Geodetic CRS: WGS 84 #--- ethnic regions ---# ethnic_regions &lt;- sf::st_read(here::here(&quot;/Users/a182501/project_set/data/nunn_2008/input/Murdock_shapefile/borders_tribes.shp&quot;)) %&gt;% st_transform(3857) ## Reading layer `borders_tribes&#39; from data source ## `/Users/a182501/project_set/data/nunn_2008/input/Murdock_shapefile/borders_tribes.shp&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 843 features and 4 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -25.35875 ymin: -34.82223 xmax: 63.50018 ymax: 37.53944 ## Geodetic CRS: WGS 84 # lat/long for slave trade centers trade_centers &lt;- readxl::read_xls(here::here(&quot;/Users/a182501/project_set/data/nunn_2008/input/nunn2008.xls&quot;)) 10.3 计算最近的贸易距离 countries_simp &lt;- rmapshaper::ms_simplify(countries) ( g_countries &lt;- ggplot(data = countries_simp) + geom_sf() + theme_void() ) 用st_centroid()来发现每一个国家的质心. countries_centroid &lt;- st_centroid(countries) ## Warning in st_centroid.sf(countries): st_centroid assumes attributes are ## constant over geometries of x ggplot()+ geom_sf(data = countries_simp)+ geom_sf(data = countries_centroid,color=&#39;red&#39;,size =0.5) ( coast_union &lt;- st_union(coast) ) ## Geometry set for 1 feature ## Geometry type: MULTILINESTRING ## Dimension: XY ## Bounding box: xmin: -20037510 ymin: -20261860 xmax: 20037510 ymax: 18428920 ## Projected CRS: WGS 84 / Pseudo-Mercator ## MULTILINESTRING ((4926419 -2317631, 4926038 -23... minum_dist_to_coast &lt;- st_nearest_points(countries_centroid, coast_union) ( g_min_dist_line &lt;- ggplot() + geom_sf(data = countries_simp) + geom_sf(data = minum_dist_to_coast, color = &quot;red&quot;) + theme_void() ) closest_pt_on_coast &lt;- lwgeom::st_endpoint(minum_dist_to_coast) g_min_dist_line + geom_sf( data = closest_pt_on_coast, color = &quot;blue&quot;, size = 2 ) + theme_void() countries_simp$nearest_pt &lt;- closest_pt_on_coast ( trade_centers_sf &lt;- trade_centers %&gt;% st_as_sf(coords = c(&quot;lon&quot;, &quot;lat&quot;), crs = 4326) %&gt;% st_transform(crs = 3857) ) ## Simple feature collection with 9 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -9168273 ymin: -2617513 xmax: -4288027 ymax: 4418219 ## Projected CRS: WGS 84 / Pseudo-Mercator ## # A tibble: 9 × 3 ## name fallingrain_name geometry ## * &lt;chr&gt; &lt;chr&gt; &lt;POINT [m]&gt; ## 1 Virginia Virginia Beach (-8458055 4418219) ## 2 Havana Habana (-9168273 2647748) ## 3 Haiti Port au Prince (-8051739 2100853) ## 4 Kingston Kingston (-8549337 2037549) ## 5 Dominica Roseau (-6835017 1723798) ## 6 Martinique Fort-de-France (-6799394 1644295) ## 7 Guyana Georgetown (-6473228 758755.9) ## 8 Salvador Salvador da Bahia (-4288027 -1457447) ## 9 Rio de Janeiro Rio (-4817908 -2617513) ggplot() + geom_sf(data = trade_centers_sf, color = &quot;red&quot;) + geom_sf(data = countries_simp, aes(geometry = geometry)) + theme_void() 参考文献 "],["appendix.html", "11 Appendix 11.1 Doing Economics 11.2 The Effect", " 11 Appendix 11.1 Doing Economics 11.2 The Effect "],["参考文献.html", "参考文献", " 参考文献 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
